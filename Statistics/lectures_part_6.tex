% defines
\def\dispxi#1{\mathbb{D}_\xi^{#1}}
\def\mathbox#1{\fbox{$\displaystyle #1$}}

% main content

% Lecture 12  ---  21.04.21
\section{Інтервальні оцінки параметрів.}
Для того, щоб перейти до поняття інтервальної оцінки, нам знадобиться деякий теоретичний мінімум щодо розподілу числових характеристик гаусівських вибірок.
\subsection{Розподіли числових характеристик гаусівських вибірок.}
Нехай є Г.С.: $\xi \sim N(a, \sigma^2)$, що породжує вибірку $\xi_1, \dots , \xi_n$ --  незалежні, гаусівські.
\begin{itemize}
 \item Маємо  вибіркове середнє $\overline{\xi} = \frac{\xi_1 + \dots + \xi_n}{n} $.
  \item  Якщо правжнє математичне сподівання $a$ відоме: $ \mathbb{D}^*_\xi = \frac{1}{n}  \sum\limits_{i = 1}^{n}{(\xi_i - a)^2} $;
  \item Інакше можемо знайти $\mathbb{D}^{**}_\xi = \frac{1}{n}  \sum\limits_{i = 1}^{n}{(\xi_i - \overline{\xi})^2}$ або $\mathbb{D}^{***}_\xi = \frac{1}{n-1}  \sum\limits_{i = 1}^{n}{(\xi_i - \overline{\xi})^2}$.
\end{itemize}
\blue{Як розподілені ці характеристики?}
\subsubsection{Вибіркове середнє.}
За властивостями гаусівських величин: \mathbox{\overline{\xi}\sim N \left( a, \dfrac{\sigma^2}{2} \right)}.
\subsubsection{Вибіркова дисперсія.}
Нехай \textit{відоме} $\mathbb{E} \xi = a \Longrightarrow \displaystyle
\dispxi{*} : \ \
\frac{n \dispxi{*}}{\sigma^2} = \frac{n \frac{1}{n}  \sum\limits_{i = 1}^{n}{(\xi_i - a)^2}}{\sigma^2} =  \sum\limits_{i = 1}^{n}{ \left( \frac{\xi_i - a}{\sigma} \right)^2 } =  \sum\limits_{i = 1}^{n}{\tilde{\xi}^2_i} \sim \chi_n^2
$.
$$
\forall i : \xi_i \sim N(a, \sigma^2) \quad \Longrightarrow \quad \tilde{\xi}_i = \frac{\xi_i - a}{\sigma} \sim N(0, 1) \quad \Longrightarrow \quad \fbox{$\displaystyle \frac{n \dispxi{*}}{ \sigma^2} \sim \chi^2_n $}
$$
Нехай $\mathbb{E} \xi$ -- \textit{невідоме}. Тоді:
$$
\dispxi{**} = \frac{1}{n}  \sum\limits_{i = 1}^{n}{(\xi_i - \overline{\xi})^2} =
\frac{1}{n}  \sum\limits_{i = 1}^{n}{\xi_i^2}  -    \left( \frac{1}{n} \sum\limits_{i = 1}^{n}{\xi_i} \right)^2 = \overline{\xi^2} - (\overline{\xi})^2
$$
Спершу розглянемо величину коваріації між $\overline{\xi}$ та $\xi_i - \overline{\xi}$:
$$
\begin{gathered}
\mathrm{cov}(\overline{\xi}, \xi_i - \overline{\xi}) = \mathbb{E} \overline{\xi} \left( \xi_i - \overline{\xi} \right) - \mathbb{E} \overline{\xi} \cdot \underbrace{\mathbb{E}\left( \xi_i - \overline{\xi} \right)}_{= a-a = 0} =
\mathbb{E} \frac{\xi_1 + \dots + \xi_n}{n} \left( \xi_i - \frac{\xi_1 + \dots + \xi_n}{n} \right) =
\\
 = \mathbb{E} \left(  \frac{\xi_1 + \dots + \xi_n}{n} \cdot \xi_i  \right)- \mathbb{E} \left( \frac{\xi_1 + \dots + \xi_n}{n} \right)^2 = \mathbb{E} \frac{\xi_i^2}{n} +  \sum\limits_{j \neq i}^{}{ \frac{\xi_i \cdot \xi_j}{n} } -
\\
- \frac{1}{n^2} \left( \mathbb{E} \xi_1^2 + \dots + \mathbb{E}\xi_n^2 + 2 \mathbb{E}\xi_1 \xi_2 + \dots + 2 \mathbb{E} \xi_{n-1}\xi_n \right) = \left| \  \begin{gathered}
 \mathbb{E} \xi_i^2 - (\mathbb{E}\xi_i)^2 = \mathbb{D}\xi_i\\
 \mathbb{E} \xi_i^2 = a^2 + \sigma^2
\end{gathered} \  \right|  =
\\
=\frac{1}{n} (a^2 + \sigma^2)  \frac{n-1}{n} \cdot  a^2 + \frac{1}{n^2} (na^2 + n\sigma^2 - 2\frac{n(n-1)}{2}a^2 )=
\\
=
\frac{a^2}{n} + \frac{\sigma^2}{n} + a^2 -   \frac{a^2}{n} -   \frac{a^2}{n} - \frac{\sigma^2}{n}  -  a^2 +  \frac{a^2}{n} = \mathbf{0}
\end{gathered}
$$
Остаточно, отримали, що $\overline{\xi}$ не корелює з $\xi_i - \overline{\xi}\ \forall i.$ Тобто:
$$
\begin{gathered}
  \mathrm{corr} (\overline{\xi}, \xi_i - \overline{ \xi}) = 0 \quad \forall i\\
  \Downarrow\\
  \mathrm{corr} \left( \overline{\xi}, \begin{bmatrix}
   \xi_1 - \overline{\xi}\\
   \vdots\\
   \xi_n - \overline{\xi}
  \end{bmatrix} \right) = 0\\
  \text{За власт. } \Downarrow \ N(a, \sigma^2)\\
   \overline{\xi} \independent\begin{bmatrix}
    \xi_1 - \overline{\xi}\\
    \vdots\\
    \xi_n - \overline{\xi}
   \end{bmatrix}
\\
\Downarrow\\
\overline{\xi} \independent  \sum\limits_{i = 1}^{n}{ (\xi_i - \overline{\xi})^2} = \dispxi{**}
\\
\text{Для гаусівської Г.С. вибіркове середнє та вибіркова дисперсія \red{є незалежними}.}
\end{gathered}
$$
Повернемося до визначення розподілу вибіркової дисперсії:
$$
\dispxi{**} = \frac{1}{n}  \sum\limits_{i = 1}^{n }{ \xi_i^2} - \left( \frac{1}{n}  \sum\limits_{i =1 }^{ n}{ \xi_i}  \right)^2 \quad \Longrightarrow \quad
\frac{1}{n}  \sum\limits_{i = 1}^{n }{ \xi_i^2} = \dispxi{**}+
\left( \frac{1}{n}  \sum\limits_{i =1 }^{ n}{ \xi_i}  \right)^2
$$
$$
\frac{\xi_i - a}{\sigma} = \tilde{\xi}_i \longrightarrow \xi_i  \quad \qquad
\chi_n^2 \sim \sum\limits_{i = 1}^{n }{ \tilde{\xi}_i^2} =
\underbrace{n \mathbb{D}_{\tilde{\xi}}^{**}}_{\chi_{n-1}^2} +
\underbrace{\left( \frac{1}{\sqrt{n}}  \sum\limits_{i =1 }^{ n}{ \tilde{\xi}_i}  \right)^2}_{N(0, 1)^2 \sim \chi_1^2}
$$
В останньому міркуванні скористалися фактом незалежності, отриманим раніше:
$$
\overline{\xi} \independent \mathbb{D}_{\xi}^{**}  \quad \Longrightarrow \quad  \left( \frac{1}{\sqrt{n}}  \sum\limits_{i =1 }^{ n}{ \tilde{\xi}_i}  \right)^2 \ \independent \ n \mathbb{D}_{\tilde{\xi}}^{**}
$$
Таким чином, довели, що $ n \mathbb{D}_{\tilde{\xi}}^{**} \sim \chi_{n-1}^2$. Розпишемо:
$$
n \mathbb{D}_{\tilde{\xi}}^{**}  =
\sum\limits_{i = 1}^{n}{\left(  \tilde{\xi}_i - \frac{\tilde{\xi}_1 + \dots + \tilde{\xi}_n}{n} \right)^2 } \!\! =  \sum\limits_{i = 1}^{n}{
 \left(   \frac{\xi_i - a}{\sigma} - \frac{(\xi_1- a)  + \dots + (\xi_n - a)}{n\sigma} \right)^2
} =
$$
$$
= \frac{1}{\sigma^2} \sum\limits_{i = 1}^{n}{
 \left(   \xi_i - a   - \frac{\xi_1  + \dots + \xi_n}{n}+ \frac{an}{n} \right)^2} = \frac{n}{\sigma^2} \cdot \frac{1}{n}  \sum\limits_{i = 1}^{ n}{\left(  \xi_i - \overline{\xi} \right)^2} = \mathbox{ \frac{n}{\sigma^2} \cdot \mathbb{D}_{\xi}^{**}}
$$
\begin{boxteo}
  Остаточно, довели такі властивості:
  $$
    \begin{array}{l}
    \text{1) } \overline{\xi} \sim N \left( a, \dfrac{\sigma^2}{n} \right)\\
  \text{2) } \dfrac{n \cdot \mathbb{D}_{\xi}^{**} }{\sigma^2} \sim \chi^2_n
  \end{array} \qquad \qquad
  \begin{array}{l}
   \text{3) }  \dfrac{n \cdot \mathbb{D}_{\xi}^{**}}{\sigma^2} \sim \chi_{n-1}^2 \ \  \text{та } \  \dfrac{(n-1) \cdot \mathbb{D}_{\xi}^{***}}{\sigma^2} \sim \chi_{n-1}^2\\
    \text{4) } \overline{\xi} \independent \mathbb{D}_{\xi}^{**}
  \end{array}
  $$
\end{boxteo}
\begin{consequence} Розглянемо деякі наслідки з попередньої теореми:
$$
  \begin{array}{l}
  \text{1) }\sqrt{n} \dfrac{\overline{ \xi} - a}{\sigma} \sim N(0,1)\\
  \ \\
\text{2) } \dfrac{n \cdot \mathbb{D}_{\xi}^{*}}{\sigma^2} \sim \chi_n^2
\end{array} \qquad \qquad
\begin{array}{l}
 \text{3) }  \mathbox{\sqrt{n-1} \frac{\overline{\xi} - a}{\sqrt{\dispxi{**}}} \sim St_{n-1}}\\
 \ \\
  \text{4) } \dfrac{n \dispxi{**}}{\sigma^2} \sim \chi_{n-1}^2
\end{array}
$$
\end{consequence}
\newpage
\subsection{Інтервальні оцінки параметрів генеральної сукупності.}
Мотивація: існує суттєвий недолік точкових оцінок --- \blue{невідома їх точність.}
\begin{defo}
 Інтервал $(\theta^*_1, \theval_2)$ називають \red{довірчим інтервалом} для параметру $\theta$ з довірчою імовірністю (надійністю) $\gamma$, якщо
 $
 \mathbb{P} \left\lbrace (\theta^*_1, \theval_2) \ni \theta \right\rbrace = \gamma
 $.
 \end{defo}
 \begin{remark}[1]
   $\theta^*_1, \theval_2$ --  випадкові величини. $\theta$ -- невідоме конкретне число. Таким чином, розглядаємо ймовірність потрапляння у інтервал як функцію від $\theta^*_1(\overrightarrow{\xi}), \theval_2(\overrightarrow{\xi})$.
 \end{remark}
 \begin{remark}[2]
 Зазвичай $\gamma = 0.9, 0.95, 0.99$. $(\theta^*_1, \theval_2)\xrightarrow[\gamma \to 1]{}  (-\i, +\i)$
 \end{remark}
\subsubsection{Знаходження точних довірчих інтервалів для гаусівської Г.С.}
\begin{enumerate}
  \item Інтервал для $\mathbb{E} \xi = a$ при відомій дисперсії:
  $$
  \sqrt{n} \dfrac{\overline{ \xi} - a}{\sigma} \sim N(0,1) \quad \Longrightarrow \quad
  \begin{gathered}
  \setlength{\fboxrule}{0.0pt}
  \includegraphics[scale=0.18]{assets/lectures_part_6-25d71e2a.png}
  \end{gathered}
  $$
  $$
  \gamma = \mathbb{P} \left\lbrace \eta \in (-t_{\gamma}, t_{\gamma}) \right\rbrace = \Laplas \left( t_{\gamma}  \right)  - \Laplas(- t_{\gamma}) = 2\Laplas \left( t_{\gamma} \right) \Longrightarrow \mathbox{t_{\gamma} = \Laplas^{-1}\left( \frac{\gamma}{2} \right) }
  $$
  $$
  \gamma = \mathbb{P} \left\lbrace   \sqrt{n} \dfrac{\overline{ \xi} - a}{\sigma} \in (-t_{\gamma}, t_{\gamma}) \right\rbrace \quad \Longrightarrow \quad \mathbox{
  \overline{\xi} - \frac{\sigma t_{\gamma}}{\sqrt{n} } < a < \overline{\xi} +  \frac{\sigma t_{\gamma}}{\sqrt{n} }
  }
  $$
  \item Інтервал для дисперсії при відомому $\mathbb{E} \xi = a$:
  $$
   \dfrac{n \cdot \mathbb{D}_{\xi}^{*}}{\sigma^2} \sim \chi_n^2 \quad \Longrightarrow \quad \begin{gathered}
   \text{Аналогічно, визначаємо інтервал на PDF:}\\
   \eta \sim \chi^2_n : \mathbb{P} \left\lbrace t_{\frac{1 + \sigma}{2}} < \eta < t_{\frac{1 - \sigma}{2}}  \right\rbrace
   \end{gathered}
  $$
  $$
  t_{\frac{1 + \sigma}{2}} <  \dfrac{n \cdot \mathbb{D}_{\xi}^{*}}{\sigma^2} < t_{\frac{1 - \sigma}{2}}
 \quad \Longrightarrow \quad
 \mathbox{ \dfrac{n \cdot \mathbb{D}_{\xi}^{*}}{t_{\frac{1 - \sigma}{2}}}  < \sigma^2 < \dfrac{n \cdot \mathbb{D}_{\xi}^{*}}{ t_{\frac{1 + \sigma}{2}} }
 }\qquad t   \text{ -- для розподілу } \chi_n^2
  $$
  \item Інтервал для дисперсії при невідомому $\mathbb{E} \xi$:
  $$
  \dfrac{n \dispxi{**}}{\sigma^2} \sim \chi_{n-1}^2  \quad \Longrightarrow \quad
  \mathbox{ \dfrac{n \cdot \mathbb{D}_{\xi}^{*}}{t^{(n-1)}_{\frac{1 - \sigma}{2}}}  < \sigma^2 < \dfrac{n \cdot \mathbb{D}_{\xi}^{*}}{ t^{(n-1)}_{\frac{1 + \sigma}{2}} }
  }\qquad  t^{(n-1)} \text{ -- для розподілу } \chi_{n-1}^2
  $$
  \item Інтервал для $\mathbb{E} \xi = a$ при невідомій дисперсії:
  $$
  \sqrt{n-1} \frac{\overline{\xi} - a}{\sqrt{\dispxi{**}}} \sim St_{n-1} \quad \Longleftarrow \quad \begin{gathered}
\text{Знов користуємося наслідком теореми 5.1 та }\\
\text{визначаємо інтервал на } f_{St_{n-1}} (x)
  \end{gathered}
  $$
  $$
  - t_{\gamma}  < \frac{\sqrt{n-1} \cdot (\overline{ \xi} - a )}{\sqrt{\mathbb{D}_{\xi}^{**}}} < t_{\gamma} \quad \Longrightarrow \quad \mathbox{
\overline{\xi} - \frac{t_{\gamma}\sqrt{\mathbb{D}_{\xi}^{**}}}{\sqrt{n-1}} < a < \overline{\xi} + \frac{t_{\gamma}\sqrt{\mathbb{D}_{\xi}^{**}}}{\sqrt{n-1}}
  }
  $$
  де  $t_{\gamma}$ -- для розподілу Стьюдента з $n-1$ ступенями вільності.
\end{enumerate}
\subsubsection{Точні довірчі інтервали для будь-яких розподілів. }
\begin{center}
 \large Загальний алгоритм пошуку точних довірчих інтервалів.
\end{center}
\begin{enumerate}
  \item Знайти таку функцію $H(\overrightarrow{x}, \theta)$, що:
  \begin{itemize}
    \item $H(\overrightarrow{\xi}, \theta)$ -- розподіл цієї величини не залежить від $\theta$.
    \item $\exists H^{-1} : \theta = H^{-1}(\overrightarrow{\xi})$.
  \end{itemize}
  \item $H(\overrightarrow{\xi}, \theta)$ -- розподіл не залежить від $\theta \ \Longrightarrow \
  \gamma = \mathbb{P} \left\lbrace t_1 < H(\overrightarrow{\xi}, \theta) < t_2 \right\rbrace
  $.
  \item Розв'язуємо відносно $\theta$. Отримаємо: $\theta_1^* (\overline{\xi}) < \theta < \theta_2^* (\overline{\xi})$.
\end{enumerate}
\newpage
\subsubsection{Асимптотичны довірчі інтервали.}
\begin{defo}
 $(\theval_{1,n} , \theval_{2,n})$ називається \red{асимптотичним довірчим інтервалом}, якщо:
$$
 \lim\limits_{n\to  \infty}{\mathbb{P} \left\lbrace  \theval_{1,n} < \theta < \theval_{2,n} \right\rbrace} = \gamma
$$
\end{defo}
\begin{center}
 \large Алгоритм пошуку асимптотичного довірчого інтервалу.
\end{center}
\begin{enumerate}
  \item $\theval$ -- точкова оцінка, яка є асимптотично нормальною (наприклад, містить суми незалежних однаково розподілених випадкових величин).
  \item $\displaystyle \frac{ \theval - \mathbb{E} \theval}{
  \sqrt{\mathbb{D} \theval}
  } \approx N(0,1) $ при великих $n$. Шукаємо симетричний довірчий інтервал:
  $$
  \Laplas (t_{\gamma}) = \Laplas(t_{\gamma}) - \Laplas(0) =  \frac{\gamma}{2} \quad \Longrightarrow \quad t_{\gamma} : \Laplas(t_{\gamma}) = \frac{\gamma}{2}
  $$
  $$
  \mathbb{P} \left\lbrace - t_{\gamma} < N(0,1) < t_{\gamma} \right\rbrace = \gamma \quad \Longrightarrow \quad  \mathbox{  \mathbb{P} \left\lbrace - t_{\gamma} <\frac{ \theval - \mathbb{E} \theval}{
  \sqrt{\mathbb{D} \theval}
  } < t_{\gamma} \right\rbrace \approx \gamma}
  $$
  \item Розв'язуючи цю нерівність відносно $\theta$, отримаємо асимптотичний довірчий интервал для $\theta$.
\end{enumerate}
\newpage



\section{
Статистичні гіпотези. Перевірка гіпотез.
}
\begin{defo}
 \red{Статистична гіпотеза} --- це довільне припущення про розподіл Г.С. або його параметри, яке можна перевірити на основі вибіркових даних.
\end{defo}
\begin{multicols}{2}
\begin{itemize}
  \item  \blue{Непараметрична гіпотеза} --- це твердження, про розподіл Г.С. Приклад: $H_0$  -- гаусівська.
  \item \blue{Параметрична гіпотеза} --- це твердження про параметри Г.С. \\ Приклад:$H_0 = Pois(\lambda)$.
  \item \blue{Проста гіпотеза} --- це гіпотеза, що повністю визначає розподіл Г.С. або його параметри.
  \item \blue{Складна гіпотеза} --- стверджує про належність Г.С. до певного сімейства розподілів.
\end{itemize}
\end{multicols}

Розглянемо $H_0$ -- \textit{основна гіпотеза}. Якщо ж $H_0$ не виправдовується, то ми приймаємо \textit{альтернативну гіпотезу} -- $H_1$ і відхиляємо $H_0$.
\begin{defo}
 \red{Статистичний критерій} --- процедура, яка на основі вибіркових даних дозволяє або прийняти $H_0$ , або відхилити $H_0$ і прийняти $H_1$.
\end{defo}
\begin{example}
  Нехай є вибірка $\xi_1 , \dots , \xi_n$, $H_0$ -- основна гіпотеза, $H_1$ -- альтернативна. \par
     Вибираємо статистику $T(\xi_1, \dots , \xi_n)$ та простір змагань $\mathbb{R}^n (\xi_1, \dots, \xi_n)$:
     \begin{center}
     \vspace*{-1em}
     \setlength{\fboxrule}{0.0pt}
   \includegraphics[scale=0.3]{assets/lectures_part_6-b1580c4d.png}
     \end{center}
  Головне питання буде полягати у виборі зазначених на малюнку областей. Вони будуть визначатися задопомогою обраної статистики. \par Припустимо: за умови виконання $H_0 : T(\xi_1, \dots, \xi_n)$ з великою імовірністю потрапляє в деяку область. Якщо статистика $T$ потрапляє в область $\omega \Rightarrow$ приймаємо $H_0$.
  \end{example}
  \textit{Розглянемо більш конкретний приклад.} Маємо: Г.С. $\xi \sim N(a,\sigma^2),
  \  \sigma $ -- відома.
  $$
   H_0 = \left\lbrace a = a_0 \right\rbrace\qquad
   H_1 = \left\lbrace a = a_1 \right\rbrace
   \qquad a_0 < a_1
   $$
$$
T(\xi_1 , \dots , \xi_n) = \frac{\xi_1 + \dots + \xi_n}{n} = \overline{\xi}
$$
Таким чином, оберемо $x \in (a_0, a_1)$ так, що:
\begin{itemize}
  \item Якщо $\overline{\xi} \leq  x$: приймаємо $H_0 \Rightarrow \omega = \left\lbrace \overline{y} \in \mathbb{R}^n : \overline{y} \leq x  \right\rbrace$.
  \item Якщо $\overline{\xi}>  x$: приймаємо $H_1 \Rightarrow \overline{\omega} = \left\lbrace \overline{y} \in \mathbb{R}^n : \overline{y} > x  \right\rbrace$.
\end{itemize}
\subsection{Помилки І-го та ІІ-го роду.}
\begin{center}
\vspace*{2em}
 \includegraphics[scale=0.4]{assets/lectures_part_6-4c5b9490.png}
\end{center}
\vspace*{1em}
\begin{itemize}
  \item Якщо \textit{істинна} гіпотеза помилково відкидається, то ця помилка називається \red{помилкою першого роду} (англ. type I errors $\alpha$ errors, \blue{false positives}).
  \item Якщо помилково приймається \textit{хибна} гіпотеза - це \red{помилка другого роду} (англ. type II errors $\beta$ errors, \blue{false negatives}).
\end{itemize}
\subsubsection{Влучність та повнота (Precision and recall).}
\vspace*{-1em}
В розпізнаванні образів, інформаційному пошуку та класифікації широко застосовуються дві метрики, які відображають наявність помилок першого і другого роду.
\begin{defo}
\red{Влучність} (англ. precision, яку також називають прогностичною значущістю позитивного результату) є часткою релевантних зразків серед знайдених.
\end{defo}
\begin{defo}
  \red{Повнота} (англ. recall, відома також як чутливість) є часткою загального числа позитивних зразків, яку було дійсно знайдено.
\end{defo}
Влучність не слід плутати з \blue{точністю} (англ. accuracy), яка є часткою правильно спрогнозованих результатів, як позитивних, так і негативних.
$$
\vspace*{-1em}
\begin{gathered}
\setlength{\fboxrule}{0.0pt}
 \includegraphics[scale=0.25]{assets/lectures_part_6-79981811.png}
 \end{gathered}
 \qquad
 \begin{gathered}
 \setlength{\fboxrule}{0.0pt}
 \includegraphics[scale=0.4]{assets/lectures_part_6-304942b8.png}
 \end{gathered}
 \vspace*{0.1em}
$$
\subsubsection{Рівень значущості та потужність критерію.}
\vspace*{-1em}
\begin{spacing}{1}
\blue{Рівень значущості критерію} --- це ймовірність помилки І-го роду:
  $$
  \mathbb{P} \left\lbrace \text{Приймаємо } H_1 \ \big| \  H_0 \text{ -- вірна} \right\rbrace = \mathbb{P} \left\lbrace \overrightarrow{\xi} \in \overline{\omega}\ \big| \  H_0 \text{ -- вірна} \right\rbrace = \alpha
  $$
\blue{Потужність критерію} дорівнює $(1 - \beta), $ де $\beta$ -- ймовірність помилки ІІ-го роду:
  $$
  \mathbb{P} \left\lbrace \text{Приймаємо } H_0 \ \big| \  H_1 \text{ -- вірна} \right\rbrace = \mathbb{P} \left\lbrace \overrightarrow{\xi} \in \omega\ \big| \  H_1 \text{ -- вірна} \right\rbrace = \beta
  $$
\end{spacing}
\textit{Повернемося до прикладу.} Саме від значущості та потужності критерію буде залежати положення ``межі'' $x$. Найчастіше вибирають значення: $\alpha = 0.01, 0.05, 0.1$.\par
Зафіксуємо рівень значущості $\alpha = 0.05$ та побудуємо критерій (знайдемо $x$).
$$
\alpha = \mathbb{P} \left\lbrace \overrightarrow{\xi} \in \overline{\omega} \  \big| \  H_0 \right\rbrace = \mathbb{P} \left\lbrace  \overline{\xi} > x  \  \big| \  a = a_0 \right\rbrace  =
$$
$$
=
\left| \begin{gathered}
 a = a_0 \Longrightarrow
 \xi_1 , \dots , \xi_n \sim N(a_0, \sigma^2)\\
 \Downarrow \\
 \overline{ \xi} = \frac{\xi_1 , \dots , \xi_n}{n}   \sim N(a_0, \sigma^2/n)
\end{gathered} \right| = \frac{1}{2} - \Laplas \left(  \sqrt{n} \frac{x - a_0}{\sigma}  \right) = \frac{1}{2} - \alpha
$$
$$
 \sqrt{n} \frac{x - a_0}{\sigma}= t_{\alpha}\quad \Longrightarrow \quad \mathbox{x = a_0 + \frac{\sigma t_{\alpha}}{\sqrt{n}} }
$$
$$
1 - \beta = 1 - \mathbb{P} \left\lbrace \overrightarrow{\xi} \in \omega \ \big| \  H_1 \right\rbrace  =
1 - \mathbb{P} \left\lbrace \overrightarrow{\xi} \in \omega \ \big| \  a= a_1 \right\rbrace = \frac{1}{2} + \Laplas \left( \sqrt{n} \cdot \frac{a_1 - x}{ \sigma}  \right)
$$
Бачимо, що зменшуючи $\alpha$ -- збільшуємо $\beta$: \mathbox{\alpha \downarrow  \Rightarrow t_{\alpha}\to \infty \Rightarrow \beta \uparrow \Rightarrow (1- \beta) \downarrow}. \par
Знайдемо рівень значущості та потужність критерію для загального випадку:
\[
\begin{split}
\alpha &= \mathbb{P} \left\lbrace  \overrightarrow{\xi} \in \overline{\omega} \ \big| \  H_0 \right\rbrace =
\infint{\begin{gathered}
 \overline{\omega}
\end{gathered}}  f_{\overline{\xi} }(x_1, \dots, x_n) \mathrm{d} x_1 \dots \mathrm{d} x_n =
\\ &=
\infint{\begin{gathered}
 \overline{\omega}
\end{gathered}}   \underbrace{f_{\xi}(x_1) \cdot \dots \cdot f_{\xi}(x_n)}_{\mathcal{L}_{H_0}(\overrightarrow{x})}\mathrm{d} x_1 \dots \mathrm{d} x_n =
\underset{\begin{gathered}
 \overline{\omega}
\end{gathered}}{\int\!\cdots\!\int}
\mathcal{L}_{H_0}(\overrightarrow{x})
\mathrm{d} x_1 \dots \mathrm{d} x_n
\end{split}
\]
Аналогічно, для потужності критерію:
\(
\
\displaystyle
\beta = \underset{\begin{gathered}
 \omega
\end{gathered}}{\int\!\cdots\!\int}
\mathcal{L}_{H_1}(\overrightarrow{x})
\mathrm{d} x_1 \dots \mathrm{d} x_n
\)\\
Зробимо висновок щодо прийняття чи відхилення гіпотези $H_0$:
\begin{itemize}
  \item Більш категоричний факт -- \blue{відхилення гіпотези} $H_0$: на рівні значущості $\alpha$, гіпотеза $H_0$ \textit{суперечить} вибірковим даним.
  \item \blue{Прийняття} $H_0$:\  -//- $H_0$ \textit{не суперечить} вибірковим даним.
\end{itemize}
\subsection{Критерій \(\chi^2\) (критерій Пірсона).}
Припустимо, є Г.С. та вибірка з неї: $\overrightarrow{ \xi} = (\xi_1, \dots, \xi_n)$. \par
Нехай $F$ -- теоретична функція розподілу $\xi$. Висуваємо гіпотезу:
$$
H_0 = \left\lbrace F(x) = F_0(x) \right\rbrace \qquad \quad H_1 = \left\lbrace F(x) \neq  F_0(x) \right\rbrace
$$
Розіб'ємо область значень Г.С. \( \mathcal{E}_\xi \) на інтервали $\Delta_1, \Delta_2, \dots, \Delta_m:$
  \ \(
   \begin{dcases}
    \Delta_i \cap \Delta_j = \emptyset \quad \forall i \neq j \\
    \bigcup_i \Delta_i =  \mathcal{E}_\xi
   \end{dcases}
  \)
Складаємо таблицю. Наведемо опис застосованих характеристик:
\begin{enumerate}
  \item Кількість елементів, що потрапили в $\Delta_k = n_k$;
  \item Середня кількість елементів, що потрапили в $\Delta_k$, якщо розподіл вгаданий правильно, тобто:
  \( \mathbb{E} \) (кількість елементів вибірки в \( \Delta_k \)) \(  = \mathbb{E} \mathrm{Bin}(n, \underbrace{\mathbb{P} \left\lbrace \xi \in \Delta_k \  \big| \  H_0 \right\rbrace}_{= p_k}) \)
\end{enumerate}
\[
 \begin{array}{l|c|c|c|c|c|c}
\text{Характеристики}   & \quad \Delta_1 \quad & \quad \Delta_2 \quad & \quad \cdots \quad & \quad \Delta_k \quad &\quad  \cdots \quad &\quad  \Delta_m \quad \\
\hline
1.\ n_k = \mathrm{card} \left\lbrace x_i \  \big| \   x_i \in \Delta_k \right\rbrace& n_1 &n_2 & \cdots & n_k& \cdots & n_m\\
\hline
2.\ \mathbb{E} n_{k, H_0}  = \mathbb{E} \mathrm{Bin}(n, p_k) = np_k
& np_1 &np_2 & \cdots & np_k& \cdots & np_m
 \end{array}
\]

\textbf{Головне завдання} може бути сформульовано наступним чином: наскільки близькими є \textit{реальні спостереження} (І рядок) до отриманих за припущенням (ІІ рядок).
Можемо використовувати для порівняння: \(  \sum\limits_{k=1}^{m}{ \frac{(n_k - np_k)^2}{np_k}} = \chi^2(n)\)
\begin{boxteo}[Пірсона про критерій \( \chi^2 \)]
 Якщо гіпотетичний розподіл вгадано правильно (тобто, \( H_0 \) справдовується), то:
 $$
 \chi^2 (n) \xrightarrow[n \to \i]{\mathrm{d}} \chi^2_{m-1}
 $$
 \textbf{Вправа:} Довести.
\end{boxteo}
\subsubsection{Застосування критерію \( \chi^2 \) для перевірки простих гіпотез.}
Якщо \( H_0 \) виконана, то за теоремою при великих \( n \ : \
\chi^2(n) \text{ має розподіл приблизно } \chi^2_{m-1}\). \par
Припустимо, що \(  \chi^2  > \chi_{m-1, \alpha}^2 \). Розглянемо можливі причини:
\begin{enumerate}
  \item Відбулася рідкісна подія ймовірності \( \alpha \); при цьому гіпотеза \( H_0 \) виконується, але є помилково відхиленною \( \Longrightarrow  \) виникає помилка І-го роду.
  \item Гіпотеза \( H_0 \) не виконується \( \Longrightarrow   H_0 \) відхиляємо, приймаємо \( H_1 \).
\end{enumerate}
Запишемо вимоги до $n, p_k$. Дані умови є суто практичними та можуть відрізнятися:
\[
 \begin{gathered}
  \forall k \in \overline{1, m}\\
np_k \geq 5
 \end{gathered} \qquad\quad \begin{cases}
  m \geq 20 \\
  np_k \geq  5
 \end{cases}
 \qquad \quad
 \begin{cases}
  m \leq 20 \\
  np_k \geq  10
 \end{cases}
\]
\subsubsection{Застосування критерію \( \chi^2 \) для перевірки складних гіпотез.}
Приклад складної гіпотези:
\(
 H_0 = \left\lbrace
\text{ Г.С. розподілена за законом Пуассона }
  \right\rbrace
\).\par
\( H_0 \) -- складна гіпотеза про розподіл Г.С.,
s -- кількість параметрів розподілу, тоді:
\[
 \chi^2 (n, \theta^*) =  \sum\limits_{i=1}^{m}{
 \frac{(n_i - np_i(\theta^*))^2}{np_i (\theta^*)}
 } \qquad \widehat{\theta} = \underset{\theta^* \in \Theta}{\arg \min}\ \chi^2 (n, \theta^*) \qquad p_i = \mathbb{P} \lbrace \!\!\!\underbrace{\xi}_{\sim P(\theta^*)}\!\!\!  < \Delta_i \rbrace
\]

\begin{boxteo}[Теорема Фішера]
Якщо виконана гіпотеза \( H_0 \), то:
\[
  \chi^2 (n) \xrightarrow[n\to\i]{\mathrm{d}}  \chi^2_{m-s-1} \qquad \chi^2 (n) = \chi^2(n, \widehat{\theta})
\]
Якщо \( \chi^2(n, \widehat{\theta}_{MLE}) < \chi^2_{m-s-1, \alpha} \), тоді:
\(
  \chi^2(n, \widehat{\theta}) <  \chi^2(n, \widehat{\theta}_{MLE})  < \chi^2_{m-s-1, \alpha}
\). \par
Тобто, якщо гіпотеза не суперечить даним при перевірці одною з оцінок параметрів, то гіпотезу можна прийняти на цьому рівні значущості.
\end{boxteo}
\subsubsection{Застосування критерію \( \chi^2 \) для перевірки незалежності.}
Нехай є Г.С.: \( \begin{bmatrix}
 \xi \\ \eta
\end{bmatrix} \). Та вибірка:
\(
\begin{bmatrix}
 \xi_1 \\ \eta_1
\end{bmatrix} ,  \dots , \begin{bmatrix}
  \xi_n \\ \eta_n
\end{bmatrix}
 \). Гіпотеза: \( H_0 = \left\lbrace \xi \independent \eta \right\rbrace \).
\begin{itemize}
  \item Вибираємо інтервали для \( \xi \) та  \( \eta \):
\(
\mathcal{E}_{\xi} = \Delta_1 \cup \cdots \cup \Delta_k, \
\mathcal{E}_{\eta} = \nabla_1 \cup \cdots \cup \nabla_l
\)
\item Складаємо таблицю, де \( n_{ij} \text{ -- кількість пар } \begin{bmatrix}
 \xi_p \\ \eta_p
\end{bmatrix} \in \Delta_i \times \nabla_j \):
\[
 \begin{array}{c|c|c|c|c|c}
 \overrightarrow{\xi} \big\backslash \overrightarrow{\eta}& \quad \nabla_1 \quad & \quad \cdots \quad & \quad \nabla_j \quad &\quad  \cdots \quad &\quad  \nabla_l \quad \\
\hline
\Delta_1 & n_{11} & \cdots & n_{1j} & \cdots & n_{1l}\\
\hline
\vdots & \vdots & \ddots & \vdots& \ddots & \vdots\\
\hline
\Delta_i & n_{i1} & \cdots & n_{ij} & \cdots & n_{il}\\
\hline
\vdots& \vdots & \ddots & \vdots & \ddots & \vdots\\
\hline
\Delta_k& n_{k1} & \cdots & n_{kj} & \cdots & n_{kl}\\
 \end{array}
\]
\item За припущенням: \( \eta \independent \xi \Longrightarrow \mathbb{P} \left\lbrace
\begin{bmatrix}
 \xi \\ \eta
\end{bmatrix} \in \Delta_i \times \nabla_j   \right\rbrace  = \mathbb{P} \left\lbrace \xi \in \Delta_i \right\rbrace \cdot \mathbb{P} \left\lbrace \eta \in \nabla_j \right\rbrace
\)\par
За ЗВЧ: \(
\begin{dcases}
\mathbb{P} \left\lbrace  \xi \in \Delta_i \right\rbrace  \xleftarrow[n\to\i]{\mathbb{P}} \dfrac{n_i^{*}}{n} = \dfrac{\sum\limits_{j=1}^{l}{n_{ij}}}{n}; \\
\mathbb{P} \left\lbrace  \eta \in \nabla_j \right\rbrace  \xleftarrow[n\to\i]{\mathbb{P}} \dfrac{n_j^{**}}{n} = \dfrac{\sum\limits_{i=1}^{k}{n_{ij}}}{n}.
\end{dcases}
 \qquad
 \mathbb{P} \left\lbrace
 \begin{bmatrix}
  \xi \\ \eta
 \end{bmatrix} \in \Delta_i \times \nabla_j   \right\rbrace  \xleftarrow[n\to\i]{\mathbb{P}} \dfrac{n_{ij}}{n}
 \)\\
 Таким чином, якщо виконується \( H_0 \), то має бути \ \( \displaystyle \frac{n_{ij}}{n} \approx \frac{n^*_i}{n} \cdot \frac{n^{**}_j}{n} \).
\end{itemize}

\begin{boxteo} Якщо виконано \( H_0 = \left\lbrace \xi \independent \eta \right\rbrace \), то:
\[
 \chi^2(n) \xrightarrow[n\to\i]{\mathrm{d}} \chi^2_{(k-1)(l-1)}(n) \qquad \quad
 \chi^2(n) =  \sum\limits_{i=1}^{k}{
  \sum\limits_{j=1}^{l}{
  \frac{\left( n_{ij} - \frac{n^*_i \cdot n^{**}_j}{n} \right)^2}{
  \frac{n^*_i \cdot n^{**}_j}{n}
  }
  }
 }
\]
\end{boxteo}
\subsection{Ранговий критерій однорідності Манна-Уітні.}
\begin{itemize}
  \item Дві незалежні Г.С.: \( \xi \) та \( \eta \). \item
  Відповідно, дві вибірки: \( \overrightarrow{\xi} = (\xi_1, \dots, \xi_m) \) та \( \overrightarrow{\eta} = (\eta_1 , \dots , \eta_n) \).\item
  Гіпотеза: \( H_0 = \left\lbrace \mathcal{F}_{\xi} = \mathcal{F}_{\eta} \right\rbrace \).\item
  Умова: обидві Г.С. мають неперервну функцію розподілу.
\end{itemize}
Спочатку побудуємо \blue{спільний} варіаційний ряд для реалізацій:
\[
  \overrightarrow{\xi} \mapsto (x_1 , \dots, x_m) \qquad \quad \overrightarrow{\eta} \mapsto (y_1 , \dots, y_n)
\]
\blue{Функція статистичного критерію}: \( \mathcal{W} \) --- сума рангів всіх елементів вибірки \( \overrightarrow{\eta} \).
\[
 W = \frac{1}{2} n (n+1) +  \sum\limits_{i=1}^{m}{
  \sum\limits_{j=1}^{n}{\index \left\lbrace \xi_i < \eta_j \right\rbrace}
 }
\]
\def\mcW{\mathcal{W}}
Знайдемо характеристики функції критерію \( \mathcal{W} \) та віднормуємо:
\begin{enumerate}
  \item \( \mathbb{E} \mcW = \dfrac{n(n+1)}{2} + \sum\limits_{i=1}^{m}{
   \sum\limits_{j=1}^{n}{ \mathbb{P} \left\lbrace \xi_i < \eta_j \right\rbrace}
  } = \dfrac{n(n+1)}{2} + mn\cdot \mathbb{P} \left\lbrace \xi < \eta \right\rbrace = \dfrac{n(n+1)}{2} + \dfrac{mn}{2} \)
  \item \(
    \displaystyle
    \mathbb{D} \mcW = \frac{mn(m+n+1)}{12}
   \)
   \item За ЦГТ: \mathbox{     \frac{\mathcal{W} - \frac{n(m+n+1)}{2}}{
        \sqrt{
        \frac{mn(m+n+1)}{12}
        }
        } \xrightarrow[m,n\to\i]{\mathrm{d}} N (0,1) } -- за умови $H_0$.
\end{enumerate}
\newpage
\subsection{Перевірка параметричних гіпотез.}
\subsubsection{Перевірка гіпотези про математичне сподівання для гаусівської Г.С.}
Нехай задано Г.С.: \( \mathcal{N}(a, \sigma) \) та гіпотезу \( H_0 = \left\lbrace  a = a_0 \right\rbrace; \ H_1 = \left\lbrace a = a_1 \right\rbrace \). \par
Надалі проведемо перевірку гіпотези про \( a  \) в гаусівській Г.С. при відомій дисперсії.
\[
 \text{ За гіпотези } H_0 : \  \sqrt{n} \cdot \frac{\overline{\xi} - a_0}{\sigma} \sim \mathcal{N}(0,1)
\]
Побудуємо критерій. Альтернативною гіпотезою можемо взяти:
\[
 \begin{gathered}
  \text{Лівостороння}\\
  \left\lbrace a <  a_0 \right\rbrace
 \end{gathered} \qquad \quad
 \begin{gathered}
  \text{Двостороння}\\
  \left\lbrace a \neq   a_0 \right\rbrace
 \end{gathered} \qquad \quad
 \begin{gathered}
  \text{Правостороння}\\
  \left\lbrace a >  a_0 \right\rbrace
 \end{gathered}
\]
\begin{itemize}
  \item Для \textit{двосторонньої} альтернативної гіпотези: \( \displaystyle
  T = \sqrt{n} \frac{\overline{x} - a}{\sigma} \Rightarrow   t : \Laplas(t) = \frac{1 - \alpha}{2}
  \).
  \item Для \textit{правосторонньої} альтернативної гіпотези:
  \( T \Longrightarrow  t : \Laplas (t) = \frac{1}{2} - \alpha
   \).
   \item Для \textit{лівосторонньої} альтернативної гіпотези:
   \( T \Longrightarrow  t : \Laplas (|t|) = \frac{1}{2} - \alpha
    \).
\end{itemize}
\subsubsection{Перевірка гіпотези про дисперсію для гаусівської Г.С.}
При невідомому математичному сподіванні можемо перевірити гіпотезу для \( \sigma^2 \):
\[
 T = \frac{n \cdot \mathbb{D}^{**}}{\sigma^2_0} \sim \chi^2_{n-1}
\]
Аналогічно будується критерій для таких альтернативних гіпотез можемо взяти:
\[
 \begin{gathered}
  \text{Лівостороння}\\
  \left\lbrace \sigma^2 <  \sigma^2_0 \right\rbrace
 \end{gathered} \qquad \quad
 \begin{gathered}
  \text{Двостороння}\\
  \left\lbrace \sigma^2 \neq   \sigma^2_0 \right\rbrace
 \end{gathered} \qquad \quad
 \begin{gathered}
  \text{Правостороння}\\
  \left\lbrace \sigma^2 >  \sigma^2_0 \right\rbrace
 \end{gathered}
\]
\newpage
\subsubsection{Гіпотези про співвідношення параметрів 2-х гаусівських Г.С.}
Маємо дві гаусівські Г.С.: \(  \xi \sim \mathcal{N}(a_1, \sigma^2_1); \ \eta \sim \mathcal{N}(a_2, \sigma^2_2)\ \mapsto \ (\xi_1 , \dots , \xi_{n_1}) ; \ (\eta_1, \dots , \eta_{n_2}) \).
\begin{enumerate}
  \item \(\displaystyle
   \sigma_1, \sigma_2 \ \blue{ -- відомі;} \  H_0 = \left\lbrace a_1 = a_2 \right\rbrace
   \  H_2 = \left\lbrace a_1 \neq (>,<) a_2 \right\rbrace
  \).\par
  Розглядаємо \(  \overline{\xi} - \overline{\eta}  \sim \mathcal{N}(a_1 - a_2, \frac{\sigma^2_1}{n_1} + \frac{\sigma_2^2}{n_2}) \):
  \[
\begin{gathered}
\frac{
(\overline{\xi} - \overline{\eta}) - (a_1  - a_2 )
}{
\sqrt{ \frac{\sigma^2_1}{n_1} + \frac{\sigma_2^2}{n_2}}
} \sim \mathcal{N}(0,1) \quad \xRightarrow{H_0 \text{ виконується}} \quad
 \frac{
 (\overline{\xi} - \overline{\eta})
 }{
\sqrt{ \frac{\sigma^2_1}{n_1} + \frac{\sigma_2^2}{n_2}}
 } \sim \mathcal{N}(0,1)
\\   T =    \frac{
  (\overline{x} - \overline{y})
  }{
 \sqrt{ \frac{\sigma^2_1}{n_1} + \frac{\sigma_2^2}{n_2}}
  } \sim \mathcal{N}(0,1) \qquad H_0 = \left\lbrace  a_1 = a_2 \right\rbrace
  \qquad H_1 = \left\lbrace a_1 < a_2 \right\rbrace
\\   H_1 : a_1 - a_2 < 0 \quad \Longrightarrow \quad  \alpha = \Laplas(-t) - \Laplas(-\i) = \frac{1}{2} - \Laplas(t) \leadsto t
\end{gathered}
  \]
  \item Якщо дисперсії \blue{невідомі}, але однакові. Гіпотеза: \( H_0 = \left\lbrace a_1 = a_2 \right\rbrace \). Маємо:
  \[
    \frac{n_1 \cdot \mathbb{D}^{**}_{\xi}}{\sigma^2} \sim \chi^2_{n_1 - 1} \text{\ та \  }
   \frac{n_2 \cdot \mathbb{D}^{**}_{\eta}}{\sigma^2} \sim \chi^2_{n_2 - 1} \Longrightarrow
   \frac{n_1 \cdot \mathbb{D}^{**}_{\xi} + n_2 \cdot \mathbb{D}^{**}_{\eta}}{\sigma^2} \sim \chi^2_{n_1 + n_2 - 1} \ (*)
  \]
  Розглянемо вираз \(\displaystyle
   \overline{\xi} - \overline{\eta} \sim \mathcal{N}\left( a_1 - a_2,
   \sigma^2 ( \frac{1}{n_1} + \frac{1}{n_2}  ) \right)\). Віднормуємо, розділивши на дисперсію. Тоді при виконанні гіпотези \( H_0 \) маємо \( (**) \): \(\displaystyle
\frac{\overline{\xi} - \overline{\eta}}{\sigma \sqrt{
\frac{1}{n_1} + \frac{1}{n_2}
}} \sim \mathcal{N}(0,1)
    \)
  \par
  Знайдемо частку від ділення виразу \( (**) \) на корінь з виразу \( (*) \):
  \[ T =
  \dfrac{\left( \overline{\xi} - \overline{\eta} \right) \cdot \sqrt{n_1 + n_2  -2}}{
   \sqrt{
  \left( \frac{1}{n_1} + \frac{1}{n_2} \right) \left( n_1 \cdot \mathbb{D}^{**}_{\xi} + n_2 \cdot \mathbb{D}^{**}_{\eta}  \right)
  }
    } \sim \frac{\mathcal{N}(0,1)\cdot \sqrt{n_1 + n_2  -2}}{\sqrt{\chi^2_{n_1 + n_2 - 2}}}  \sim \mathrm{St}_{n_1 + n_2 - 2}
  \]
\item Як перевірити рівність дисперсій? Перевіряємо гіпотезу:
\(
 H_0= \left\lbrace \sigma_1^2 = \sigma_2^2 \right\rbrace
\).\par
Розглядаючи попередньо отримані факти, приходимо до вигляду критерію:
\[
 T = \frac{\mathbb{D}^{***}_{\xi}}{\mathbb{D}^{***}_{\eta}} \sim \mathcal{F}_{n_1, n_2}
\]
\end{enumerate}
\subsubsection{Гіпотези про параметри бернулівської Г.С.}
Нехай проведено \( n \) випробувань з \( p \) -- імовірністю успіху в одному. \( k \) -- кількість успіхів, випадкова величина. Гіпотеза: \( H_0 = \left\lbrace p = p_0 \right\rbrace \ n>>1\).\par
Розглянемо оцінку ймовірності успіху:
\[
p^* = \frac{k}{n} \sim \frac{\mathrm{Bin}(n, p)}{n} \overset{\text{ЦГТ}}\approx \frac{\mathcal{N}(np,npq)}{n} = \mathcal{N}\left( p, \frac{pq}{n} \right)
\]
\[
 T =\left| H_0 \text{ виконується} \right| = \frac{\sqrt{n} \cdot (p^* -  p_0)}{\sqrt{p_0(1-p_0)}} \sim N(0,1)
\]
Для двох бернулівських Г.С.: \( (n_1, p_1); \ (n_2, p_2);\ H_0= \left\lbrace p_1 = p_2 \right\rbrace \). Кількість успіхів:
\[
 k_1 - k_2 \sim \overbrace{\mathrm{Bin}(n_1, p_1) - \mathrm{Bin}(n_2, p_2)}^{\independent}
\]
\[
 p_1^* - p_2^* = \frac{k_1}{n_1} - \frac{k_2}{n_2} \sim \frac{\mathrm{Bin}(n_1, p_1)}{n_1}
 - \frac{\mathrm{Bin}(n_2, p_2)}{n_1} \approx \mathcal{N} \left( p_1 - p_2 , \frac{p_1q_1}{n_1} + \frac{p_2q_2}{n_2} \right)
\]
\[
 H_0 = \left\lbrace p_1 = p_2 \right\rbrace \quad \Rightarrow\quad \frac{k_1}{n_1} - \frac{k_2}{n_2}= p^*_1- p_2^* \approx \mathcal{N} \left(
0, p_1 (1-p_1)\cdot \left( \frac{1}{n_1} + \frac{1}{n_2} \right)
  \right)
\]
\[
 T = \frac{p_1^* - p^*_2}{
 \sqrt{
 \left( \frac{k_1 + k_2}{n_1 + n_2} \right) \left( 1 - \frac{k_1 + k_2}{n_1 + n_2} \right)
 \left( \frac{1}{n_1} + \frac{1}{n_2}\right)
 }
 }
\]
При великих \( n_1, n_2: T\approx \mathcal{N}(0,1) \).
\begin{center}
\textbf{	--- Happy End --- }\\
{\tiny Без некоторых рисунков. }
\end{center}
